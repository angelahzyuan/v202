---
title: Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN
openreview: UsmVj32aPL
abstract: 'Masked image modeling, an emerging self-supervised pre-training method,
  has shown impressive success across numerous downstream vision tasks with Vision
  transformers. Its underlying idea is simple: a portion of the input image is masked
  out and then reconstructed via a pre-text task. However, the working principle behind
  MIM is not well explained, and previous studies insist that MIM primarily works
  for the Transformer family but is incompatible with CNNs. In this work, we observe
  that MIM essentially teaches the model to learn better middle-order interactions
  among patches for more generalized feature extraction. We then propose an Architecture-Agnostic
  Masked Image Modeling framework (A$^2$MIM), which is compatible with both Transformers
  and CNNs in a unified way. Extensive experiments on popular benchmarks show that
  A$^2$MIM learns better representations without explicit design and endows the backbone
  model with the stronger capability to transfer to various downstream tasks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li23af
month: 0
tex_title: Architecture-Agnostic Masked Image Modeling -- From {V}i{T} back to {CNN}
firstpage: 20149
lastpage: 20167
page: 20149-20167
order: 20149
cycles: false
bibtex_author: Li, Siyuan and Wu, Di and Wu, Fang and Zang, Zelin and Li, Stan Z.
author:
- given: Siyuan
  family: Li
- given: Di
  family: Wu
- given: Fang
  family: Wu
- given: Zelin
  family: Zang
- given: Stan Z.
  family: Li
date: 2023-07-03
address: 
container-title: Proceedings of the 40th International Conference on Machine Learning
volume: '202'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 7
  - 3
pdf: https://proceedings.mlr.press/v202/li23af/li23af.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
